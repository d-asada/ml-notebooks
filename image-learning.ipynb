{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 必要なライブラリのインストール\n",
    "!pip install cloudmlmagic keras\n",
    "%load_ext cloudmlmagic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Cloud Magickの初期化\n",
    "%%ml_init -projectId asobiba-196608 -bucket asobiba-ml-bucket -scaleTier BASIC_GPU -region asia-east1 -runtimeVersion 1.2\n",
    "{'install_requires': ['keras', 'h5py', 'Pillow']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%ml_code\n",
    "\n",
    "# モデル定義\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "model = InceptionV3(weights='imagenet')\n",
    "\n",
    "url = 'https://storage.googleapis.com/asobiba-ml-bucket/datasets.npz'\n",
    "response = requests.get(url)\n",
    "dataset = np.load(BytesIO(response.content))\n",
    "\n",
    "X_dataset = dataset['features']\n",
    "y_dataset = dataset['labels']\n",
    "\n",
    "X_dataset = preprocess_input(X_dataset)\n",
    "y_dataset = np_utils.to_categorical(y_dataset)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_dataset, y_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# 転移学習用のモデル\n",
    "intermediate_layer_model = Model(inputs=model.input, outputs=model.layers[311].output)\n",
    "\n",
    "# レイヤー追加\n",
    "x = intermediate_layer_model.output\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Transfer learning model, all layers are trainable at this moment\n",
    "transfer_model = Model(inputs=intermediate_layer_model.input, outputs=predictions)\n",
    "\n",
    "print(pd.DataFrame(transfer_model.layers).tail())\n",
    "\n",
    "# Freeze all layers\n",
    "for layer in transfer_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Unfreeze the last layers, so that only these layers are trainable.\n",
    "transfer_model.layers[312].trainable = True\n",
    "transfer_model.layers[313].trainable = True\n",
    "\n",
    "transfer_model.compile(loss='categorical_crossentropy',\n",
    "                       optimizer='adam',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'trainingOutput': {}, u'state': u'QUEUED', u'trainingInput': {u'runtimeVersion': u'1.2', u'packageUris': [u'gs://asobiba-ml-bucket/mlmagic__1524471999.tar.gz'], u'region': u'asia-east1', u'pythonModule': u'trainer.task', u'scaleTier': u'BASIC_GPU'}, u'createTime': u'2018-04-23T08:27:01Z', u'jobId': u'mlmagic__1524471999'}\n"
     ]
    }
   ],
   "source": [
    "%%ml_run cloud\n",
    "\n",
    "# モデル学習\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "transfer_model.fit(X_train, y_train, epochs=30,\n",
    "                   verbose=2,\n",
    "                   validation_data=(X_test, y_test))\n",
    "loss, acc = transfer_model.evaluate(X_test, y_test)\n",
    "print('Loss {}, Accuracy {}'.format(loss, acc))\n",
    "\n",
    "K.set_learning_phase(0)  # test\n",
    "sess = K.get_session()\n",
    "\n",
    "from tensorflow.python.framework import graph_util\n",
    "\n",
    "# Make GraphDef of Transfer Model\n",
    "g_trans = sess.graph\n",
    "g_trans_def = graph_util.convert_variables_to_constants(sess,\n",
    "                                                        g_trans.as_graph_def(),\n",
    "                                                        [transfer_model.output.name.replace(':0','')])\n",
    "\n",
    "# Image Converter Model\n",
    "with tf.Graph().as_default() as g_input:\n",
    "    input_b64 = tf.placeholder(shape=(1,), dtype=tf.string, name='input')\n",
    "    input_bytes = tf.decode_base64(input_b64[0])\n",
    "    image = tf.image.decode_image(input_bytes)\n",
    "    image_f = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    input_image = tf.expand_dims(image_f, 0)\n",
    "    output = tf.identity(input_image, name='input_image')\n",
    "\n",
    "g_input_def = g_input.as_graph_def()\n",
    "\n",
    "with tf.Graph().as_default() as g_combined:\n",
    "    x = tf.placeholder(tf.string, name=\"input_b64\")\n",
    "\n",
    "    im, = tf.import_graph_def(g_input_def,\n",
    "                              input_map={'input:0': x},\n",
    "                              return_elements=[\"input_image:0\"])\n",
    "\n",
    "    pred, = tf.import_graph_def(g_trans_def,\n",
    "                                input_map={transfer_model.input.name: im,\n",
    "                                          'batch_normalization_1/keras_learning_phase:0': False},\n",
    "                                return_elements=[transfer_model.output.name])\n",
    "\n",
    "    pred_index = tf.argmax(pred, axis=-1)\n",
    "    books = tf.constant([ \"serverless\", \"production_ready\", \"devops\" ], name=\"label\")\n",
    "    book_name = tf.gather(books, pred_index)\n",
    "\n",
    "    with tf.Session() as sess2:\n",
    "        inputs = {\"inputs\": tf.saved_model.utils.build_tensor_info(x)}\n",
    "        outputs = {\"pred_index\": tf.saved_model.utils.build_tensor_info(pred_index), \n",
    "                   \"score\": tf.saved_model.utils.build_tensor_info(pred), \n",
    "                   \"book_name\": tf.saved_model.utils.build_tensor_info(book_name)}\n",
    "        signature = tf.saved_model.signature_def_utils.build_signature_def(\n",
    "            inputs=inputs,\n",
    "            outputs=outputs,\n",
    "            method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
    "        )\n",
    "\n",
    "        # save as SavedModel\n",
    "        b = tf.saved_model.builder.SavedModelBuilder('gs://asobiba-ml-bucket/keras-mlengine/savedmodel')\n",
    "        b.add_meta_graph_and_variables(sess2,\n",
    "                                       [tf.saved_model.tag_constants.SERVING],\n",
    "                                       signature_def_map={'serving_default': signature})\n",
    "        b.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "exceptions must be old-style classes or derived from BaseException, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dee40b6ca9d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0;34m\"stop\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: exceptions must be old-style classes or derived from BaseException, not str"
     ]
    }
   ],
   "source": [
    "# 一時停止用\n",
    "raise \"stop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Cloud ML Enginge のモデルおよびAPI作成\n",
    "!gcloud ml-engine models create MLBooks\n",
    "!gcloud ml-engine versions create v5 --model MLBooks --runtime-version 1.2 --origin gs://asobiba-ml-bucket/keras-mlengine/savedmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 予測テスト\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "\n",
    "PROJECTID = 'asobiba-196608'\n",
    "projectID = 'projects/{}'.format(PROJECTID)\n",
    "modelName = 'MLBooks'\n",
    "modelID = '{}/models/{}'.format(projectID, modelName)\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "ml = discovery.build('ml', 'v1', credentials=credentials)\n",
    "\n",
    "with open('input/s_serverless_image.jpg', 'rb') as f:\n",
    "    b64_x = f.read()\n",
    "\n",
    "import base64\n",
    "import json\n",
    "\n",
    "b64_x = base64.urlsafe_b64encode(b64_x)\n",
    "input_instance = dict(inputs=b64_x)\n",
    "input_instance = json.loads(json.dumps(input_instance))\n",
    "request_body = {\"instances\": [input_instance]}\n",
    "\n",
    "request = ml.projects().predict(name=modelID, body=request_body)\n",
    "try:\n",
    "    response = request.execute()\n",
    "except errors.HttpError as err:\n",
    "    # Something went wrong with the HTTP transaction.\n",
    "    # To use logging, you need to 'import logging'.\n",
    "    print('There was an HTTP error during the request:')\n",
    "    print(err._get_reason())\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
